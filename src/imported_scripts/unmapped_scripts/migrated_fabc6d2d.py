{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-auth-oauthlib in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (1.2.1)\n",
      "Requirement already satisfied: google-auth-httplib2 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: google-api-python-client in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (2.154.0)\n",
      "Requirement already satisfied: pandas in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: duckdb in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (1.1.3)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from google-auth-oauthlib) (2.36.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from google-auth-oauthlib) (2.0.0)\n",
      "Requirement already satisfied: httplib2>=0.19.0 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from google-auth-httplib2) (0.22.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from google-api-python-client) (2.23.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.66.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (5.28.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.25.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from google-auth>=2.15.0->google-auth-oauthlib) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from httplib2>=0.19.0->google-auth-httplib2) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-auth-oauthlib) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/srvo/venvs/datasci/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-auth-oauthlib google-auth-httplib2 google-api-python-client pandas duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching calendar data...\n",
      "Loading token from token.pickle\n",
      "Fetching events from 2021-08-15T05:28:03.957401+00:00 to 2024-11-27T05:28:03.957401+00:00\n",
      "Fetching page of events (current total: 0)...\n",
      "Fetched 250 events (total: 250)\n",
      "Fetching page of events (current total: 250)...\n",
      "Fetched 250 events (total: 500)\n",
      "Fetching page of events (current total: 500)...\n",
      "Fetched 250 events (total: 750)\n",
      "Fetching page of events (current total: 750)...\n",
      "Fetched 250 events (total: 1000)\n",
      "Fetching page of events (current total: 1000)...\n",
      "Fetched 250 events (total: 1250)\n",
      "Fetching page of events (current total: 1250)...\n",
      "Fetched 250 events (total: 1500)\n",
      "Fetching page of events (current total: 1500)...\n",
      "Fetched 250 events (total: 1750)\n",
      "Fetching page of events (current total: 1750)...\n",
      "Fetched 250 events (total: 2000)\n",
      "Fetching page of events (current total: 2000)...\n",
      "Fetched 250 events (total: 2250)\n",
      "Fetching page of events (current total: 2250)...\n",
      "Fetched 110 events (total: 2360)\n",
      "Total events fetched: 2360\n",
      "Total events after deduplication: 2360\n",
      "Total attendees fetched: 2360\n",
      "Events data sample:\n",
      "                                      event_id  \\\n",
      "0  vsctukkk2oavvb0ht0uublihc9_20241127T000000Z   \n",
      "2  5brtvp8i8enh4duk2mnl6tc1qa_20241126T210000Z   \n",
      "3          iq7b0rmpamuu28s3f2qn8qli98_20241126   \n",
      "4  38788foc7bm1jvmgmt4p7370jb_20241126T010000Z   \n",
      "5                   aqbjrerq8d460j4gqdh9qu3f78   \n",
      "\n",
      "                                            summary  \\\n",
      "0                     Gwen Hofmeyr and Sloane Ortel   \n",
      "2  *Radical Planners* All Community Monthly Session   \n",
      "3                                              Home   \n",
      "4                     Provo women trans/femme night   \n",
      "5                      Abdulrahman and Sloane Ortel   \n",
      "\n",
      "                                         description  \\\n",
      "0  Event Name: Catch up/collaborate<br><br>Has it...   \n",
      "2  âœ¨ Radical Planners Monthly Agenda & Notes âœ¨\\nðŸ““...   \n",
      "3                                                      \n",
      "4                                                      \n",
      "5  Event Name: Adviser Consultation\\n\\nLearn more...   \n",
      "\n",
      "                                            location  \\\n",
      "0                   meetings.dialpad.com/sloaneortel   \n",
      "2  https://us06web.zoom.us/j/7295757237?pwd=enlZU...   \n",
      "3                                                      \n",
      "4  Provo Bicycle Collective, 397 E 200 N, Provo, ...   \n",
      "5  Join the meeting:  https://meetings.dialpad.co...   \n",
      "\n",
      "                 start_time                  end_time  \\\n",
      "0 2024-11-27 00:00:00+00:00 2024-11-27 01:00:00+00:00   \n",
      "2 2024-11-26 21:00:00+00:00 2024-11-26 22:30:00+00:00   \n",
      "3 2024-11-26 00:00:00+00:00 2024-11-27 00:00:00+00:00   \n",
      "4 2024-11-26 01:00:00+00:00 2024-11-26 03:00:00+00:00   \n",
      "5 2024-11-25 17:30:00+00:00 2024-11-25 18:15:00+00:00   \n",
      "\n",
      "                    created                          updated     status  \\\n",
      "0 2023-10-11 00:11:16+00:00 2024-11-06 20:16:53.534000+00:00  confirmed   \n",
      "2 2023-09-04 16:41:59+00:00 2024-11-20 14:46:35.313000+00:00  tentative   \n",
      "3 2023-04-17 22:24:59+00:00 2024-01-24 15:09:12.588000+00:00  confirmed   \n",
      "4 2024-04-25 21:46:41+00:00 2024-11-14 16:55:42.803000+00:00  confirmed   \n",
      "5 2024-11-22 12:18:40+00:00 2024-11-22 15:44:05.445000+00:00  confirmed   \n",
      "\n",
      "            organizer_email  ...  \\\n",
      "0        sloane@ethicic.com  ...   \n",
      "2  info@radicalplanners.com  ...   \n",
      "3        sloane@ethicic.com  ...   \n",
      "4        sloane@ethicic.com  ...   \n",
      "5        sloane@ethicic.com  ...   \n",
      "\n",
      "                                           html_link hangout_link  \\\n",
      "0  https://www.google.com/calendar/event?eid=dnNj...                \n",
      "2  https://www.google.com/calendar/event?eid=NWJy...                \n",
      "3  https://www.google.com/calendar/event?eid=aXE3...                \n",
      "4  https://www.google.com/calendar/event?eid=Mzg3...                \n",
      "5  https://www.google.com/calendar/event?eid=YXFi...                \n",
      "\n",
      "                                     conference_data attendees_count  \\\n",
      "0  {'entryPoints': [{'entryPointType': 'video', '...               2   \n",
      "2                                                 {}               1   \n",
      "3                                                 {}               0   \n",
      "4                                                 {}               0   \n",
      "5                                                 {}               3   \n",
      "\n",
      "   response_status         attendee_email attendee_name  \\\n",
      "0                   gwenhofmeyr@gmail.com                 \n",
      "2                      sloane@ethicic.com                 \n",
      "3                                    None          None   \n",
      "4                                    None          None   \n",
      "5                      sloane@ethicic.com                 \n",
      "\n",
      "  attendee_response_status attendee_optional attendee_comment  \n",
      "0                 accepted             False                   \n",
      "2                 accepted             False                   \n",
      "3                     None               NaN             None  \n",
      "4                     None               NaN             None  \n",
      "5                 declined             False                   \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Attendees columns: ['kind', 'etag', 'id', 'status', 'htmlLink', 'created', 'updated', 'summary', 'description', 'location', 'creator', 'organizer', 'start', 'end', 'iCalUID', 'sequence', 'attendees', 'hangoutLink', 'conferenceData', 'reminders', 'eventType', 'guestsCanInviteOthers', 'privateCopy', 'transparency', 'attachments', 'recurringEventId', 'originalStartTime', 'extendedProperties', 'endTimeUnspecified', 'visibility', 'source', 'colorId', 'outOfOfficeProperties', 'workingLocationProperties', 'guestsCanSeeOtherGuests', 'event_id', 'email', 'name', 'response_status']\n",
      "Connecting to DuckDB...\n",
      "Creating tables...\n",
      "Inserting events...\n",
      "Processing 2360 events...\n",
      "Inserting attendees...\n",
      "Processing 2360 attendees...\n",
      "\n",
      "Verification:\n",
      "Events in database: 2360\n",
      "Attendees in database: 2360\n",
      "Average attendees per event: 1.00\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Simple pipeline to get calendar data into DuckDB\"\"\"\n",
    "    con = None\n",
    "    try:\n",
    "        # Fetch all calendar data\n",
    "        print(\"Fetching calendar data...\")\n",
    "        events_df, attendees_list = fetch_calendar_data()  # Now expecting DataFrame and list\n",
    "\n",
    "        # Convert attendees list to DataFrame if needed\n",
    "        if isinstance(attendees_list, list):\n",
    "            attendees_df = pd.DataFrame(attendees_list)\n",
    "        else:\n",
    "            attendees_df = attendees_list\n",
    "\n",
    "        # Add explicit validation and debug output\n",
    "        if events_df is None or attendees_df is None:\n",
    "            print(\"Error: One or both DataFrames are None\")\n",
    "            return\n",
    "\n",
    "        if not isinstance(events_df, pd.DataFrame):\n",
    "            print(f\"Error: Invalid events data type. Expected DataFrame, got: {type(events_df)}\")\n",
    "            return\n",
    "\n",
    "        if not isinstance(attendees_df, pd.DataFrame):\n",
    "            print(f\"Error: Invalid attendees data type. Expected DataFrame, got: {type(attendees_df)}\")\n",
    "            return\n",
    "\n",
    "        # Check for required columns in events_df\n",
    "        required_event_columns = ['start_time', 'summary', 'event_id']\n",
    "        missing_event_columns = [col for col in required_event_columns if col not in events_df.columns]\n",
    "        if missing_event_columns:\n",
    "            print(f\"Error: Missing columns in events_df: {missing_event_columns}\")\n",
    "            return\n",
    "\n",
    "        # Initialize missing columns in attendees_df with default values\n",
    "        required_attendee_columns = ['event_id', 'email', 'name', 'response_status']\n",
    "        for col in required_attendee_columns:\n",
    "            if col not in attendees_df.columns:\n",
    "                if col == 'event_id':\n",
    "                    # Generate event_id based on the index if missing\n",
    "                    attendees_df[col] = [f'event_{i}' for i in range(len(attendees_df))]\n",
    "                elif col == 'email':\n",
    "                    attendees_df[col] = 'unknown@example.com'\n",
    "                elif col == 'name':\n",
    "                    attendees_df[col] = 'Unknown Attendee'\n",
    "                elif col == 'response_status':\n",
    "                    attendees_df[col] = 'needsAction'\n",
    "\n",
    "        # Handle missing or None values in required columns\n",
    "        attendees_df['event_id'] = attendees_df['event_id'].fillna(f'event_unknown')\n",
    "        attendees_df['email'] = attendees_df['email'].fillna('unknown@example.com')\n",
    "        attendees_df['name'] = attendees_df['name'].fillna('Unknown Attendee')\n",
    "        attendees_df['response_status'] = attendees_df['response_status'].fillna('needsAction')\n",
    "\n",
    "        # Remove any rows where event_id is still null (shouldn't happen with our fixes above)\n",
    "        attendees_df = attendees_df.dropna(subset=['event_id'])\n",
    "\n",
    "        # Generate unique IDs for events if event_id doesn't exist\n",
    "        if 'event_id' not in events_df.columns:\n",
    "            events_df['event_id'] = events_df.apply(\n",
    "                lambda row: f\"{row['start_time'].strftime('%Y%m%d%H%M')}_{row['summary'][:30].replace(' ', '_')}\",\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "        # Remove duplicates from events_df based on the generated event_id\n",
    "        events_df = events_df.drop_duplicates(subset=['event_id'], keep='first')\n",
    "\n",
    "        # Print the actual data for debugging\n",
    "        print(f\"Total events after deduplication: {len(events_df)}\")\n",
    "        print(f\"Total attendees fetched: {len(attendees_df)}\")\n",
    "        print(f\"Events data sample:\\n{events_df.head()}\")\n",
    "        print(f\"Attendees columns: {attendees_df.columns.tolist()}\")  # Debug line\n",
    "\n",
    "        # Connect to DuckDB and create tables\n",
    "        print(\"Connecting to DuckDB...\")\n",
    "        con = duckdb.connect('calendar.duckdb')\n",
    "\n",
    "        # Create tables if they don't exist\n",
    "        print(\"Creating tables...\")\n",
    "        con.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS events (\n",
    "                event_id VARCHAR PRIMARY KEY,\n",
    "                summary VARCHAR,\n",
    "                start_time TIMESTAMP,\n",
    "                end_time TIMESTAMP,\n",
    "                organizer_email VARCHAR,\n",
    "                organizer_name VARCHAR,\n",
    "                attendees_count INTEGER\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "        con.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS attendees (\n",
    "                event_id VARCHAR NOT NULL,\n",
    "                email VARCHAR NOT NULL,\n",
    "                name VARCHAR,\n",
    "                response_status VARCHAR\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "        # Insert data with additional validation\n",
    "        print(\"Inserting events...\")\n",
    "        if not events_df.empty:\n",
    "            print(f\"Processing {len(events_df)} events...\")\n",
    "            con.execute(\"DELETE FROM events\")  # Clear existing data\n",
    "            con.execute(\"\"\"\n",
    "                INSERT INTO events \n",
    "                SELECT event_id, summary, start_time, end_time, organizer_email, organizer_name, attendees_count \n",
    "                FROM events_df\n",
    "            \"\"\")\n",
    "        else:\n",
    "            print(\"Warning: events DataFrame is empty\")\n",
    "\n",
    "        print(\"Inserting attendees...\")\n",
    "        if not attendees_df.empty:\n",
    "            print(f\"Processing {len(attendees_df)} attendees...\")\n",
    "            con.execute(\"DELETE FROM attendees\")\n",
    "            # Only select the columns that match the table structure\n",
    "            attendees_df = attendees_df[['event_id', 'email', 'name', 'response_status']]\n",
    "            con.execute(\"\"\"\n",
    "                INSERT INTO attendees \n",
    "                SELECT event_id, email, name, response_status FROM attendees_df\n",
    "            \"\"\")\n",
    "        else:\n",
    "            print(\"Warning: attendees DataFrame is empty\")\n",
    "\n",
    "        # Detailed verification\n",
    "        event_count = con.execute(\"SELECT COUNT(*) FROM events\").fetchone()[0]\n",
    "        attendee_count = con.execute(\"SELECT COUNT(*) FROM attendees\").fetchone()[0]\n",
    "        print(f\"\\nVerification:\")\n",
    "        print(f\"Events in database: {event_count}\")\n",
    "        print(f\"Attendees in database: {attendee_count}\")\n",
    "        print(f\"Average attendees per event: {attendee_count/event_count if event_count > 0 else 0:.2f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        print(f\"Error type: {type(e)}\")\n",
    "        import traceback\n",
    "        print(f\"Traceback: {traceback.format_exc()}\")\n",
    "    finally:\n",
    "        if con:\n",
    "            con.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading token from token.pickle\n",
      "Fetching events from 2021-08-15T05:43:46.180008+00:00 to 2024-11-27T05:43:46.180008+00:00\n",
      "Fetching page of events (current total: 0)...\n",
      "Fetched 250 events (total: 250)\n",
      "Fetching page of events (current total: 250)...\n",
      "Fetched 250 events (total: 500)\n",
      "Fetching page of events (current total: 500)...\n",
      "Fetched 250 events (total: 750)\n",
      "Fetching page of events (current total: 750)...\n",
      "Fetched 250 events (total: 1000)\n",
      "Fetching page of events (current total: 1000)...\n",
      "Fetched 250 events (total: 1250)\n",
      "Fetching page of events (current total: 1250)...\n",
      "Fetched 250 events (total: 1500)\n",
      "Fetching page of events (current total: 1500)...\n",
      "Fetched 250 events (total: 1750)\n",
      "Fetching page of events (current total: 1750)...\n",
      "Fetched 250 events (total: 2000)\n",
      "Fetching page of events (current total: 2000)...\n",
      "Fetched 250 events (total: 2250)\n",
      "Fetching page of events (current total: 2250)...\n",
      "Fetched 110 events (total: 2360)\n",
      "Total events fetched: 2360\n",
      "Error uploading to MotherDuck: Invalid token format. Token should be a valid JWT with header, payload, and signature\n",
      "Full error details: ValueError\n"
     ]
    }
   ],
   "source": [
    "def upload_to_motherduck(db_path='contacts.duckdb'):\n",
    "    \"\"\"\n",
    "    Upload calendar data to MotherDuck using environment variables\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from dotenv import load_dotenv\n",
    "    \n",
    "    try:\n",
    "        # Load environment variables\n",
    "        load_dotenv()\n",
    "        \n",
    "        # Get and validate token\n",
    "        motherduck_token = os.getenv('MOTHERDUCK_TOKEN')\n",
    "        if not motherduck_token:\n",
    "            raise ValueError(\"MOTHERDUCK_TOKEN not found in .env file\")\n",
    "        \n",
    "        # Validate token format (should be a JWT token)\n",
    "        token_parts = motherduck_token.split('.')\n",
    "        if len(token_parts) != 3:\n",
    "            raise ValueError(\"Invalid token format. Token should be a valid JWT with header, payload, and signature\")\n",
    "            \n",
    "        # Create connection string\n",
    "        md_connection_string = f\"md:calendar_data_cloud?motherduck_token={motherduck_token}\"\n",
    "        \n",
    "        # Test connection before proceeding\n",
    "        test_con = duckdb.connect(md_connection_string)\n",
    "        test_con.execute(\"SELECT 1\")  # Simple test query\n",
    "        test_con.close()\n",
    "        \n",
    "        # Connect to local database first\n",
    "        local_con = duckdb.connect(db_path)\n",
    "        \n",
    "        print(\"Uploading calendar data to MotherDuck...\")\n",
    "        \n",
    "        # Connect to MotherDuck with the validated token\n",
    "        md_con = duckdb.connect(md_connection_string)\n",
    "        print(\"Connected to MotherDuck\")\n",
    "        \n",
    "        # Create events table with proper schema\n",
    "        md_con.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS events (\n",
    "                event_id VARCHAR,\n",
    "                summary VARCHAR,\n",
    "                description VARCHAR,\n",
    "                location VARCHAR,\n",
    "                start_time TIMESTAMP,\n",
    "                end_time TIMESTAMP,\n",
    "                created TIMESTAMP,\n",
    "                updated TIMESTAMP,\n",
    "                status VARCHAR,\n",
    "                organizer_email VARCHAR,\n",
    "                organizer_name VARCHAR,\n",
    "                html_link VARCHAR,\n",
    "                hangout_link VARCHAR,\n",
    "                conference_data VARCHAR,\n",
    "                attendees_count INTEGER,\n",
    "                response_status VARCHAR,\n",
    "                last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "        # Create attendees table with proper schema\n",
    "        md_con.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS attendees (\n",
    "                event_id VARCHAR,\n",
    "                email VARCHAR,\n",
    "                name VARCHAR,\n",
    "                response_status VARCHAR,\n",
    "                optional BOOLEAN,\n",
    "                comment VARCHAR,\n",
    "                last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "            )\n",
    "        \"\"\")\n",
    "        \n",
    "        # Copy data from local to MotherDuck\n",
    "        md_con.execute(\"\"\"\n",
    "            INSERT INTO events (\n",
    "                event_id, summary, description, location, start_time, end_time,\n",
    "                created, updated, status, organizer_email, organizer_name,\n",
    "                html_link, hangout_link, conference_data, attendees_count,\n",
    "                response_status\n",
    "            ) SELECT \n",
    "                event_id, summary, description, location, start_time, end_time,\n",
    "                created, updated, status, LOWER(TRIM(organizer_email)), organizer_name,\n",
    "                html_link, hangout_link, conference_data, attendees_count,\n",
    "                response_status\n",
    "            FROM local_con.events\n",
    "        \"\"\")\n",
    "\n",
    "        md_con.execute(\"\"\"\n",
    "            INSERT INTO attendees (\n",
    "                event_id, email, name, response_status, optional, comment\n",
    "            ) SELECT \n",
    "                event_id, LOWER(TRIM(email)), name, response_status, optional, comment\n",
    "            FROM local_con.attendees\n",
    "        \"\"\")\n",
    "        \n",
    "        # Verify data upload\n",
    "        events_count = md_con.execute(\"SELECT COUNT(*) FROM events\").fetchone()[0]\n",
    "        attendees_count = md_con.execute(\"SELECT COUNT(*) FROM attendees\").fetchone()[0]\n",
    "        \n",
    "        print(f\"\\nVerification Results:\")\n",
    "        print(f\"Total events uploaded: {events_count}\")\n",
    "        print(f\"Total attendees uploaded: {attendees_count}\")\n",
    "        \n",
    "        # Show sample of recent events\n",
    "        print(\"\\nRecent Events Sample:\")\n",
    "        recent_events = md_con.execute(\"\"\"\n",
    "            SELECT \n",
    "                event_id, summary, start_time, end_time, attendees_count\n",
    "            FROM events\n",
    "            ORDER BY start_time DESC\n",
    "            LIMIT 5\n",
    "        \"\"\").fetchdf()\n",
    "        print(recent_events)\n",
    "        \n",
    "        print(\"\\nDatabase successfully uploaded to MotherDuck!\")\n",
    "        \n",
    "        # Close connections\n",
    "        local_con.close()\n",
    "        md_con.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading to MotherDuck: {str(e)}\")\n",
    "        print(\"Full error details:\", e.__class__.__name__)\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Fetch and store calendar data locally\n",
    "    df, events = fetch_calendar_data()\n",
    "    \n",
    "    if isinstance(events, pd.DataFrame) and not events.empty:\n",
    "        write_events_to_duckdb(events)\n",
    "    \n",
    "    # Upload to MotherDuck\n",
    "    upload_to_motherduck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching calendar events from 2021-08-01T00:00:00+00:00 to 2024-11-27T04:45:13.998168+00:00\n",
      "Fetched 2360 events...\n",
      "Total events fetched: 2360\n",
      "Processed 2360 events with 7106 attendees\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from datetime import datetime, timedelta, UTC\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "\n",
    "# Update scopes to include all required calendar permissions\n",
    "SCOPES = [\n",
    "    'https://www.googleapis.com/auth/calendar.readonly',\n",
    "    'https://www.googleapis.com/auth/calendar.events.readonly',\n",
    "    'https://www.googleapis.com/auth/calendar'\n",
    "]\n",
    "\n",
    "def get_google_calendar_service():\n",
    "    \"\"\"Get or refresh Google Calendar credentials\"\"\"\n",
    "    creds = None\n",
    "    token_path = os.path.join(os.path.dirname('/Users/srvo/Development/.ipynb_checkpoints/calendar/credentials.json'), 'token.pickle')\n",
    "    \n",
    "    # Check for existing token\n",
    "    if os.path.exists(token_path):\n",
    "        with open(token_path, 'rb') as token:\n",
    "            creds = pickle.load(token)\n",
    "    \n",
    "    # Refresh if needed\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            try:\n",
    "                creds.refresh(Request())\n",
    "            except Exception as e:\n",
    "                print(f\"Error refreshing credentials: {e}\")\n",
    "                creds = None\n",
    "        \n",
    "        if not creds:\n",
    "            try:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                    '/Users/srvo/Development/.ipynb_checkpoints/calendar/credentials.json', SCOPES)\n",
    "                creds = flow.run_local_server(port=0)\n",
    "                \n",
    "                # Save credentials\n",
    "                with open(token_path, 'wb') as token:\n",
    "                    pickle.dump(creds, token)\n",
    "            except Exception as e:\n",
    "                raise Exception(f\"Failed to authenticate: {e}\")\n",
    "    \n",
    "    return build('calendar', 'v3', credentials=creds)\n",
    "\n",
    "def extract_event_details(event):\n",
    "    \"\"\"Extract relevant details from calendar event\"\"\"\n",
    "    details = {\n",
    "        'event_id': event.get('id'),\n",
    "        'summary': event.get('summary', ''),\n",
    "        'description': event.get('description', ''),\n",
    "        'location': event.get('location', ''),\n",
    "        'start_time': event.get('start', {}).get('dateTime', event.get('start', {}).get('date', '')),\n",
    "        'end_time': event.get('end', {}).get('dateTime', event.get('end', {}).get('date', '')),\n",
    "        'created': event.get('created', ''),\n",
    "        'updated': event.get('updated', ''),\n",
    "        'status': event.get('status', ''),\n",
    "        'organizer_email': event.get('organizer', {}).get('email', ''),\n",
    "        'organizer_name': event.get('organizer', {}).get('displayName', ''),\n",
    "        'html_link': event.get('htmlLink', ''),\n",
    "        'hangout_link': event.get('hangoutLink', ''),\n",
    "        'conference_data': str(event.get('conferenceData', {})),\n",
    "        'attendees_count': len(event.get('attendees', [])),\n",
    "        'response_status': event.get('responseStatus', ''),\n",
    "    }\n",
    "    \n",
    "    # Extract attendee information\n",
    "    attendees = event.get('attendees', [])\n",
    "    attendee_details = []\n",
    "    for attendee in attendees:\n",
    "        attendee_info = {\n",
    "            'event_id': event.get('id'),\n",
    "            'email': attendee.get('email', ''),\n",
    "            'name': attendee.get('displayName', ''),\n",
    "            'response_status': attendee.get('responseStatus', ''),\n",
    "            'optional': attendee.get('optional', False),\n",
    "            'organizer': attendee.get('organizer', False),\n",
    "            'comment': attendee.get('comment', '')\n",
    "        }\n",
    "        attendee_details.append(attendee_info)\n",
    "    \n",
    "    return pd.DataFrame([details]), pd.DataFrame(attendee_details)\n",
    "\n",
    "def fetch_calendar_data():\n",
    "    \"\"\"Fetch calendar events and return comprehensive DataFrame\"\"\"\n",
    "    try:\n",
    "        service = get_google_calendar_service()\n",
    "        \n",
    "        # Set start time to August 1, 2021\n",
    "        start_time = datetime(2021, 8, 1, tzinfo=UTC).isoformat()\n",
    "        end_time = datetime.now(UTC).isoformat()\n",
    "        \n",
    "        print(f\"Fetching calendar events from {start_time} to {end_time}\")\n",
    "        \n",
    "        events = []\n",
    "        page_token = None\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                events_result = service.events().list(\n",
    "                    calendarId='primary',\n",
    "                    timeMin=start_time,\n",
    "                    timeMax=end_time,\n",
    "                    maxResults=2500,\n",
    "                    singleEvents=True,\n",
    "                    orderBy='startTime',\n",
    "                    pageToken=page_token\n",
    "                ).execute()\n",
    "                \n",
    "                current_events = events_result.get('items', [])\n",
    "                if current_events:\n",
    "                    events.extend(current_events)\n",
    "                    print(f\"Fetched {len(current_events)} events...\")\n",
    "                \n",
    "                page_token = events_result.get('nextPageToken')\n",
    "                if not page_token:\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching page: {e}\")\n",
    "                break\n",
    "        \n",
    "        print(f\"Total events fetched: {len(events)}\")\n",
    "        \n",
    "        if not events:\n",
    "            print('No events found.')\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Process events\n",
    "        events_df = pd.DataFrame()\n",
    "        attendees_df = pd.DataFrame()\n",
    "        \n",
    "        for event in events:\n",
    "            event_details_df, attendee_details_df = extract_event_details(event)\n",
    "            events_df = pd.concat([events_df, event_details_df], ignore_index=True)\n",
    "            attendees_df = pd.concat([attendees_df, attendee_details_df], ignore_index=True)\n",
    "        \n",
    "        print(f\"Processed {len(events_df)} events with {len(attendees_df)} attendees\")\n",
    "        \n",
    "        # Calculate analytics directly with pandas\n",
    "        top_organizers = events_df.groupby(['organizer_email', 'organizer_name']).size().reset_index(name='event_count').sort_values('event_count', ascending=False)\n",
    "        \n",
    "        frequent_attendees = attendees_df.groupby(['email', 'name']).size().reset_index(name='attendance_count').sort_values('attendance_count', ascending=False)\n",
    "        \n",
    "        meeting_stats = pd.DataFrame({\n",
    "            'total_events': [len(events_df)],\n",
    "            'avg_attendees': [events_df['attendees_count'].mean()],\n",
    "            'unique_organizers': [events_df['organizer_email'].nunique()],\n",
    "            'virtual_meetings': [events_df['hangout_link'].notna().sum()]\n",
    "        })\n",
    "        \n",
    "        # Return dictionary of DataFrames\n",
    "        return {\n",
    "            'events': events_df,\n",
    "            'attendees': attendees_df,\n",
    "            'top_organizers': top_organizers,\n",
    "            'frequent_attendees': frequent_attendees,\n",
    "            'meeting_stats': meeting_stats\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in fetch_calendar_data: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fetch_calendar_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading token from token.pickle\n",
      "Fetching calendar events from 2021-08-15T04:49:37.633156+00:00 to 2024-11-27T04:49:37.633156+00:00\n",
      "Fetched 2360 events...\n",
      "Total events fetched: 2360\n",
      "\n",
      "Unique contacts found: 1346\n",
      "\n",
      "Top domains:\n",
      "domain\n",
      "gmail.com               423\n",
      "responsiblealpha.com     22\n",
      "yahoo.com                11\n",
      "vfar.org                  9\n",
      "altruist.com              8\n",
      "hotmail.com               7\n",
      "nasdaq.com                7\n",
      "puro.earth                7\n",
      "outlook.com               7\n",
      "venturecapital.org        6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Source distribution:\n",
      "source\n",
      "attendee     1286\n",
      "organizer      60\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of contacts:\n",
      "                         email name               domain     source  \\\n",
      "9465        sloane@ethicic.com               ethicic.com   attendee   \n",
      "9464     gwenhofmeyr@gmail.com                 gmail.com   attendee   \n",
      "9461  info@radicalplanners.com       radicalplanners.com  organizer   \n",
      "9456   almahmoud999@icloud.com                icloud.com   attendee   \n",
      "9457   mohamedmamduh@gmail.com                 gmail.com   attendee   \n",
      "\n",
      "                    event_time  \n",
      "9465 2024-11-27 00:00:00+00:00  \n",
      "9464 2024-11-27 00:00:00+00:00  \n",
      "9461 2024-11-26 21:00:00+00:00  \n",
      "9456 2024-11-25 17:30:00+00:00  \n",
      "9457 2024-11-25 17:30:00+00:00  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from datetime import datetime, timezone, UTC, timedelta\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "from pathlib import Path\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/calendar.readonly']\n",
    "\n",
    "def get_google_calendar_service():\n",
    "    \"\"\"Get or refresh Google Calendar credentials\"\"\"\n",
    "    creds = None\n",
    "    \n",
    "    # Look for token in current directory and .ipynb_checkpoints\n",
    "    token_paths = [\n",
    "        'token.pickle',\n",
    "        '.ipynb_checkpoints/calendar/token.pickle',\n",
    "        '.ipynb_checkpoints/token.pickle'\n",
    "    ]\n",
    "    \n",
    "    # Look for credentials in current directory and .ipynb_checkpoints\n",
    "    cred_paths = [\n",
    "        'credentials.json',\n",
    "        '.ipynb_checkpoints/calendar/credentials.json',\n",
    "        '.ipynb_checkpoints/credentials.json'\n",
    "    ]\n",
    "    \n",
    "    # Try to load existing token\n",
    "    for token_path in token_paths:\n",
    "        if os.path.exists(token_path):\n",
    "            print(f\"Loading token from {token_path}\")\n",
    "            with open(token_path, 'rb') as token:\n",
    "                creds = pickle.load(token)\n",
    "            break\n",
    "    \n",
    "    # If credentials need refresh or don't exist\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            print(\"Refreshing credentials...\")\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            # Look for credentials file\n",
    "            cred_file = None\n",
    "            for cred_path in cred_paths:\n",
    "                if os.path.exists(cred_path):\n",
    "                    print(f\"Using credentials from {cred_path}\")\n",
    "                    cred_file = cred_path\n",
    "                    break\n",
    "            \n",
    "            if not cred_file:\n",
    "                raise FileNotFoundError(\"No credentials.json found in any expected location\")\n",
    "            \n",
    "            flow = InstalledAppFlow.from_client_secrets_file(cred_file, SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        \n",
    "        # Save the credentials\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "    \n",
    "    try:\n",
    "        service = build('calendar', 'v3', credentials=creds)\n",
    "        return service\n",
    "    except Exception as e:\n",
    "        print(f\"Error building service: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def fetch_calendar_data(lookback_days=1200):\n",
    "    \"\"\"Fetch calendar events and return DataFrame of unique attendees\"\"\"\n",
    "    service = get_google_calendar_service()\n",
    "    \n",
    "    if service is None:\n",
    "        print(\"Failed to initialize Google Calendar service\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Calculate time range using timezone-aware datetime\n",
    "    now = datetime.now(UTC)\n",
    "    start_time = (now - timedelta(days=lookback_days)).isoformat()\n",
    "    end_time = now.isoformat()\n",
    "    \n",
    "    print(f\"Fetching calendar events from {start_time} to {end_time}\")\n",
    "    \n",
    "    try:\n",
    "        all_attendees = []\n",
    "        page_token = None\n",
    "        total_events = 0\n",
    "        \n",
    "        while True:\n",
    "            events_result = service.events().list(\n",
    "                calendarId='primary',\n",
    "                timeMin=start_time,\n",
    "                timeMax=end_time,\n",
    "                maxResults=2500,\n",
    "                singleEvents=True,\n",
    "                orderBy='startTime',\n",
    "                pageToken=page_token\n",
    "            ).execute()\n",
    "            \n",
    "            events = events_result.get('items', [])\n",
    "            total_events += len(events)\n",
    "            print(f\"Fetched {total_events} events...\")\n",
    "            \n",
    "            for event in events:\n",
    "                # Get event time with proper handling of both datetime and date formats\n",
    "                event_time = event.get('start', {}).get('dateTime')\n",
    "                if not event_time:\n",
    "                    # If dateTime is not available, use date and append a default time\n",
    "                    date_only = event.get('start', {}).get('date')\n",
    "                    if date_only:\n",
    "                        event_time = f\"{date_only}T00:00:00Z\"\n",
    "                \n",
    "                # Get organizer\n",
    "                if 'organizer' in event:\n",
    "                    organizer = {\n",
    "                        'email': event['organizer'].get('email', ''),\n",
    "                        'name': event['organizer'].get('displayName', ''),\n",
    "                        'source': 'organizer',\n",
    "                        'event_id': event['id'],\n",
    "                        'event_summary': event.get('summary', ''),\n",
    "                        'event_time': event_time\n",
    "                    }\n",
    "                    all_attendees.append(organizer)\n",
    "                \n",
    "                # Get attendees\n",
    "                for attendee in event.get('attendees', []):\n",
    "                    attendee_info = {\n",
    "                        'email': attendee.get('email', ''),\n",
    "                        'name': attendee.get('displayName', ''),\n",
    "                        'source': 'attendee',\n",
    "                        'event_id': event['id'],\n",
    "                        'event_summary': event.get('summary', ''),\n",
    "                        'event_time': event_time\n",
    "                    }\n",
    "                    all_attendees.append(attendee_info)\n",
    "            \n",
    "            page_token = events_result.get('nextPageToken')\n",
    "            if not page_token:\n",
    "                break\n",
    "        \n",
    "        print(f\"Total events fetched: {total_events}\")\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(all_attendees)\n",
    "        \n",
    "        # Clean and deduplicate\n",
    "        if not df.empty:\n",
    "            df['email'] = df['email'].str.lower().str.strip()\n",
    "            df['domain'] = df['email'].str.split('@').str[1]\n",
    "            # Parse datetime with explicit format handling\n",
    "            df['event_time'] = pd.to_datetime(df['event_time'], format='mixed', utc=True)\n",
    "            \n",
    "            # Get most recent interaction for each email\n",
    "            df = df.sort_values('event_time', ascending=False).drop_duplicates(subset=['email'], keep='first')\n",
    "            \n",
    "            print(f\"\\nUnique contacts found: {len(df)}\")\n",
    "            print(\"\\nTop domains:\")\n",
    "            print(df['domain'].value_counts().head(10))\n",
    "            \n",
    "            print(\"\\nSource distribution:\")\n",
    "            print(df['source'].value_counts())\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching calendar data: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Fetch and display unique contacts\n",
    "    df = fetch_calendar_data()\n",
    "    \n",
    "    if not df.empty:\n",
    "        # Display sample\n",
    "        print(\"\\nSample of contacts:\")\n",
    "        print(df[['email', 'name', 'domain', 'source', 'event_time']].head())\n",
    "        \n",
    "        # Optionally save to CSV\n",
    "        # df.to_csv('calendar_contacts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading token from token.pickle\n",
      "Fetching calendar events from 2021-08-15T04:53:55.266218+00:00 to 2024-11-27T04:53:55.266218+00:00\n",
      "Fetched 2360 events...\n",
      "Total events fetched: 2360\n",
      "\n",
      "Unique contacts found: 1346\n",
      "\n",
      "Top domains:\n",
      "domain\n",
      "gmail.com               423\n",
      "responsiblealpha.com     22\n",
      "yahoo.com                11\n",
      "vfar.org                  9\n",
      "altruist.com              8\n",
      "hotmail.com               7\n",
      "nasdaq.com                7\n",
      "puro.earth                7\n",
      "outlook.com               7\n",
      "venturecapital.org        6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Source distribution:\n",
      "source\n",
      "attendee     1286\n",
      "organizer      60\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Database Statistics:\n",
      "   total_contacts  unique_domains  unique_sources      earliest_event  \\\n",
      "0            1346             623               2 2021-08-27 10:30:00   \n",
      "\n",
      "         latest_event  \n",
      "0 2024-11-26 17:00:00  \n",
      "\n",
      "Top Domains in Database:\n",
      "                 domain  count  percentage\n",
      "0             gmail.com    423   31.426449\n",
      "1  responsiblealpha.com     22    1.634473\n",
      "2             yahoo.com     11    0.817236\n",
      "3              vfar.org      9    0.668648\n",
      "4          altruist.com      8    0.594354\n",
      "5           hotmail.com      7    0.520059\n",
      "6           outlook.com      7    0.520059\n",
      "7            puro.earth      7    0.520059\n",
      "8            nasdaq.com      7    0.520059\n",
      "9              bench.co      6    0.445765\n",
      "\n",
      "Source Distribution:\n",
      "      source  count\n",
      "0   attendee   1286\n",
      "1  organizer     60\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from datetime import datetime, timezone, UTC, timedelta  # Added timedelta\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from googleapiclient.discovery import build\n",
  