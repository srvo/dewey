{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Podcast Database Statistics:\n",
                        "   total_episodes  months_covered    earliest_episode      latest_episode  \\\n",
                        "0              63              37 2019-09-11 01:53:00 2024-09-10 14:55:00   \n",
                        "\n",
                        "   avg_duration_min  episodes_with_transcript  \n",
                        "0        338.374132                         0  \n",
                        "\n",
                        "Recent Episodes Sample:\n",
                        "                                               title           published  \\\n",
                        "0                   New Crops for a Changing Climate 2024-09-10 14:55:00   \n",
                        "1                      Divestment Without Dissonance 2024-08-02 18:52:52   \n",
                        "2  Klement, Cassandras, and the Concept of Innova... 2024-02-13 14:30:00   \n",
                        "3  The Carbon Market Coterie feat. Mark Campanale... 2024-01-24 19:15:00   \n",
                        "4  What the Bedroom Can Teach the Boardroom feat.... 2023-12-28 22:00:00   \n",
                        "\n",
                        "   duration_minutes                                description_preview  \n",
                        "0        496.912079  <p>Jed Wheeler discusses the development of ne...  \n",
                        "1        426.981361  <p>Sloane Ortel and Ashby Monk are joined by K...  \n",
                        "2        384.755645  <p>Wow! We were fortunate enough to have had J...  \n",
                        "3        439.039321  <p>This carbon special featuring Mark Campanal...  \n",
                        "4        383.661497  <p>What an exciting show for our LAST episode ...  \n",
                    ],
                },
            ],
            "source": [
                "import json\n",
                "import pandas as pd\n",
                "import duckdb\n",
                "from pathlib import Path\n",
                "import glob\n",
                "\n",
                'def load_podcast_data(base_path="/Users/srvo/Development/archive/podcast_analysis"):\n',
                '    """Load and combine podcast metadata and transcripts"""\n',
                "    try:\n",
                "        # Load metadata files\n",
                "        with open(f\"{base_path}/analysis/episodes_metadata.json\", 'r') as f:\n",
                "            episodes_metadata = json.load(f)\n",
                "        \n",
                "        with open(f\"{base_path}/analysis/summary.json\", 'r') as f:\n",
                "            summary = json.load(f)\n",
                "            \n",
                "        # Create DataFrame from metadata\n",
                "        df_metadata = pd.DataFrame(episodes_metadata)\n",
                "        \n",
                "        # Load transcripts\n",
                "        transcripts = {}\n",
                '        transcript_files = glob.glob(f"{base_path}/episodes/*.txt")\n',
                "        \n",
                "        for file_path in transcript_files:\n",
                "            episode_id = Path(file_path).stem  # Get filename without extension\n",
                "            try:\n",
                "                with open(file_path, 'r', encoding='utf-8') as f:\n",
                "                    transcripts[episode_id] = f.read()\n",
                "            except Exception as e:\n",
                '                print(f"Error reading transcript {file_path}: {str(e)}")\n',
                "                transcripts[episode_id] = None\n",
                "        \n",
                "        # Add transcripts to DataFrame\n",
                "        df_metadata['transcript'] = df_metadata['link'].apply(\n",
                "            lambda x: transcripts.get(x.split('/')[-1], None)\n",
                "        )\n",
                "        \n",
                "        # Convert audio_length to numeric\n",
                "        df_metadata['audio_length'] = pd.to_numeric(df_metadata['audio_length'], errors='coerce')\n",
                "        \n",
                "        # Add duration in minutes\n",
                "        df_metadata['duration_minutes'] = df_metadata['audio_length'].fillna(0) / (1024 * 1024 * 8 / 60)  # Assuming MP3 bitrate of 128kbps\n",
                "        \n",
                "        # Connect to DuckDB\n",
                "        con = duckdb.connect('podcast_data.duckdb')\n",
                "        \n",
                "        # Create table\n",
                '        con.execute("""\n',
                "            CREATE TABLE IF NOT EXISTS podcast_episodes (\n",
                "                title VARCHAR,\n",
                "                link VARCHAR PRIMARY KEY,\n",
                "                published TIMESTAMP,\n",
                "                description VARCHAR,\n",
                "                audio_url VARCHAR,\n",
                "                audio_type VARCHAR,\n",
                "                audio_length BIGINT,\n",
                "                duration_minutes DOUBLE,\n",
                "                transcript VARCHAR,\n",
                "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
                "            )\n",
                '        """)\n',
                "        \n",
                "        # Insert data\n",
                '        con.execute("DELETE FROM podcast_episodes")  # Clear existing data\n',
                '        con.execute("""\n',
                "            INSERT INTO podcast_episodes (\n",
                "                title, link, published, description, \n",
                "                audio_url, audio_type, audio_length,\n",
                "                duration_minutes, transcript\n",
                "            )\n",
                "            SELECT \n",
                "                title, link, \n",
                "                STRPTIME(published, '%a, %d %b %Y %H:%M:%S GMT'),\n",
                "                description, audio_url, audio_type, \n",
                "                CAST(audio_length AS BIGINT),\n",
                "                duration_minutes,\n",
                "                transcript\n",
                "            FROM df_metadata\n",
                '        """)\n',
                "        \n",
                "        # Print summary statistics\n",
                '        print("\\nPodcast Database Statistics:")\n',
                '        stats = con.execute("""\n',
                "            SELECT \n",
                "                COUNT(*) as total_episodes,\n",
                "                COUNT(DISTINCT DATE_TRUNC('month', published)) as months_covered,\n",
                "                MIN(published) as earliest_episode,\n",
                "                MAX(published) as latest_episode,\n",
                "                AVG(duration_minutes) as avg_duration_min,\n",
                "                COUNT(CASE WHEN transcript IS NOT NULL THEN 1 END) as episodes_with_transcript\n",
                "            FROM podcast_episodes\n",
                '        """).fetchdf()\n',
                "        print(stats)\n",
                "        \n",
                "        # Show sample episodes\n",
                '        print("\\nRecent Episodes Sample:")\n',
                '        recent = con.execute("""\n',
                "            SELECT \n",
                "                title,\n",
                "                published,\n",
                "                duration_minutes,\n",
                "                LEFT(description, 100) as description_preview\n",
                "            FROM podcast_episodes\n",
                "            ORDER BY published DESC\n",
                "            LIMIT 5\n",
                '        """).fetchdf()\n',
                "        print(recent)\n",
                "        \n",
                "        # Close connection\n",
                "        con.close()\n",
                "        \n",
                "        return True\n",
                "        \n",
                "    except Exception as e:\n",
                '        print(f"Error processing podcast data: {str(e)}")\n',
                '        print("Full error details:", e.__class__.__name__)\n',
                "        return False\n",
                "\n",
                'if __name__ == "__main__":\n',
                "    load_podcast_data()",
            ],
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 63 episodes in database\n",
                        "Found 62 transcript files\n",
                        "\n",
                        "Found 62 potential matches\n",
                        "Found 0 unmatched files\n",
                        "\n",
                        "Sample matches:\n",
                        "File: How_To_Get_Hired_by_an_Asset_Owner_Featuring_Recruiter_Charles_Skorina.txt\n",
                        "Matched to: How To Get Hired by an Asset Owner Featuring Recruiter Charles Skorina\n",
                        "Confidence: 0.91\n",
                        "\n",
                        "File: Divesting_From_The_Prison-Industrial_Complex_With_Ethic's_Jay_Lipman.txt\n",
                        "Matched to: Divesting From The Prison-Industrial Complex With Ethic's Jay Lipman\n",
                        "Confidence: 0.94\n",
                        "\n",
                        "File: Fermenting_Innovation_with_Anna_Marie_Wagner_and_Gingko_Bioworks.txt\n",
                        "Matched to: Fermenting Innovation with Anna Marie Wagner and Gingko Bioworks\n",
                        "Confidence: 0.93\n",
                        "\n",
                        "File: Rethinking_Risk_With_UC_Regents_Rick_Bookstaber.txt\n",
                        "Matched to: Rethinking Risk With UC Regents’ Rick Bookstaber\n",
                        "Confidence: 0.93\n",
                        "\n",
                        "File: Innovation_Backed_by_Violence_featuring_Caitlin_Rosenthal.txt\n",
                        "Matched to: Innovation Backed by Violence featuring Caitlin Rosenthal\n",
                        "Confidence: 0.94\n",
                        "\n",
                        "\n",
                        "Successfully updated 62 episodes with transcripts\n",
                    ],
                },
            ],
            "source": [
                "import duckdb\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "import glob\n",
                "from difflib import SequenceMatcher\n",
                "import re\n",
                "\n",
                "def clean_title(title):\n",
                '    """Clean title for matching"""\n',
                "    return re.sub(r'[^a-zA-Z0-9\\s]', '', title.lower())\n",
                "\n",
                "def similarity_score(a, b):\n",
                '    """Calculate similarity between two strings"""\n',
                "    return SequenceMatcher(None, clean_title(a), clean_title(b)).ratio()\n",
                "\n",
                "def match_transcripts(db_path='podcast_data.duckdb', \n",
                '                     transcript_dir="/Users/srvo/Development/archive/podcast_analysis/episodes"):\n',
                "    try:\n",
                "        # Connect to database\n",
                "        con = duckdb.connect(db_path)\n",
                "        \n",
                "        # Get episodes from database\n",
                '        episodes = con.execute("""\n',
                "            SELECT \n",
                "                title,\n",
                "                link,\n",
                "                published,\n",
                "                transcript\n",
                "            FROM podcast_episodes\n",
                "            ORDER BY published DESC\n",
                '        """).fetchdf()\n',
                "        \n",
                '        print(f"Found {len(episodes)} episodes in database")\n',
                "        \n",
                "        # Get transcript files\n",
                '        transcript_files = glob.glob(f"{transcript_dir}/*.txt")\n',
                '        print(f"Found {len(transcript_files)} transcript files")\n',
                "        \n",
                "        # Track matches\n",
                "        matches = []\n",
                "        unmatched_files = []\n",
                "        \n",
                "        # For each transcript file\n",
                "        for file_path in transcript_files:\n",
                "            file_name = Path(file_path).stem\n",
                "            best_match = None\n",
                "            best_score = 0\n",
                "            \n",
                "            # Find best matching episode\n",
                "            for _, episode in episodes.iterrows():\n",
                "                score = similarity_score(file_name, episode['title'])\n",
                "                if score > best_score and score > 0.6:  # Threshold for matching\n",
                "                    best_score = score\n",
                "                    best_match = episode\n",
                "            \n",
                "            if best_match is not None:\n",
                "                matches.append({\n",
                "                    'file': file_path,\n",
                "                    'episode_title': best_match['title'],\n",
                "                    'score': best_score\n",
                "                })\n",
                "            else:\n",
                "                unmatched_files.append(file_path)\n",
                "        \n",
                '        print(f"\\nFound {len(matches)} potential matches")\n',
                '        print(f"Found {len(unmatched_files)} unmatched files")\n',
                "        \n",
                "        # Show sample matches\n",
                '        print("\\nSample matches:")\n',
                "        for match in matches[:5]:\n",
                "            print(f\"File: {Path(match['file']).name}\")\n",
                "            print(f\"Matched to: {match['episode_title']}\")\n",
                "            print(f\"Confidence: {match['score']:.2f}\")\n",
                "            print()\n",
                "        \n",
                "        # Show unmatched files\n",
                "        if unmatched_files:\n",
                '            print("\\nUnmatched files:")\n',
                "            for file in unmatched_files[:5]:\n",
                "                print(Path(file).name)\n",
                "        \n",
                "        # Ask for confirmation\n",
                '        should_update = input("\\nWould you like to update the database with these matches? (y/n): ")\n',
                "        if should_update.lower() == 'y':\n",
                "            updates = 0\n",
                "            for match in matches:\n",
                "                try:\n",
                "                    with open(match['file'], 'r', encoding='utf-8') as f:\n",
                "                        transcript = f.read()\n",
                "                        \n",
                '                    con.execute("""\n',
                "                        UPDATE podcast_episodes \n",
                "                        SET transcript = ?\n",
                "                        WHERE title = ?\n",
                '                    """, [transcript, match[\'episode_title\']])\n',
                "                    updates += 1\n",
                "                except Exception as e:\n",
                "                    print(f\"Error updating {match['episode_title']}: {str(e)}\")\n",
                "            \n",
                '            print(f"\\nSuccessfully updated {updates} episodes with transcripts")\n',
                "        \n",
                "        return matches, unmatched_files\n",
                "        \n",
                "    except Exception as e:\n",
                '        print(f"Error matching transcripts: {str(e)}")\n',
                '        print("Full error details:", e.__class__.__name__)\n',
                "        return [], []\n",
                "    finally:\n",
                "        con.close()\n",
                "\n",
                'if __name__ == "__main__":\n',
                "    matches, unmatched = match_transcripts()",
            ],
        },
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python (Data Science)",
            "language": "python",
            "name": "datasci",
        },
        "language_info": {
            "codemirror_mode": {"name": "ipython", "version": 3},
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.7",
        },
    },
    "nbformat": 4,
    "nbformat_minor": 2,
}
