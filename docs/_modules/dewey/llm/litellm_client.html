<!DOCTYPE html>

<html lang="en" data-content_root="../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>dewey.llm.litellm_client &#8212; Dewey (TUI) 0.1.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="../../../_static/basic.css?v=b08954a9" />
    <link rel="stylesheet" type="text/css" href="../../../_static/alabaster.css?v=27fed22d" />
    <script src="../../../_static/documentation_options.js?v=01f34227"></script>
    <script src="../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for dewey.llm.litellm_client</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;LiteLLM client for handling LLM calls across different providers.</span>

<span class="sd">This module provides a unified interface for interacting with different</span>
<span class="sd">LLM providers using the LiteLLM library.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">field</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">litellm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">litellm</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">ModelResponse</span><span class="p">,</span>
    <span class="n">completion</span><span class="p">,</span>
    <span class="n">completion_cost</span><span class="p">,</span>
    <span class="n">embedding</span><span class="p">,</span>
    <span class="n">get_model_info</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">dewey.llm.exceptions</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">LLMAuthenticationError</span><span class="p">,</span>
    <span class="n">LLMConnectionError</span><span class="p">,</span>
    <span class="n">LLMRateLimitError</span><span class="p">,</span>
    <span class="n">LLMResponseError</span><span class="p">,</span>
    <span class="n">LLMTimeoutError</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="c1"># Path to config files</span>
<span class="c1"># CONFIG_PATH = Path(&quot;/Users/srvo/dewey/src/dewey/llm/config.yaml&quot;)</span>
<span class="n">DEWEY_CONFIG_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;/Users/srvo/dewey/config/dewey.yaml&quot;</span><span class="p">)</span>
<span class="n">AIDER_MODEL_METADATA_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s2">&quot;~/.aider.model.metadata.json&quot;</span><span class="p">))</span>


<div class="viewcode-block" id="Message">
<a class="viewcode-back" href="../../../dewey.llm.html#dewey.llm.litellm_client.Message">[docs]</a>
<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Message</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Message format for LLM conversations.&quot;&quot;&quot;</span>

    <span class="n">role</span><span class="p">:</span> <span class="nb">str</span>  <span class="c1"># &quot;system&quot;, &quot;user&quot;, &quot;assistant&quot;, &quot;tool&quot;</span>
    <span class="n">content</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># For &quot;tool&quot; roles</span></div>



<div class="viewcode-block" id="LiteLLMConfig">
<a class="viewcode-back" href="../../../dewey.llm.html#dewey.llm.litellm_client.LiteLLMConfig">[docs]</a>
<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">LiteLLMConfig</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Configuration for LiteLLM client.&quot;&quot;&quot;</span>

    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;gpt-3.5-turbo&quot;</span>
    <span class="n">api_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">organization_id</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">base_url</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">timeout</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">60</span>
    <span class="n">max_retries</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">fallback_models</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="nb">list</span><span class="p">)</span>
    <span class="n">proxy</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">cache_folder</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;.litellm_cache&quot;</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">metadata</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="nb">dict</span><span class="p">)</span>
    <span class="n">litellm_provider</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span></div>



<div class="viewcode-block" id="LiteLLMClient">
<a class="viewcode-back" href="../../../dewey.llm.html#dewey.llm.litellm_client.LiteLLMClient">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">LiteLLMClient</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Client for interacting with various LLM providers using LiteLLM.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="LiteLLMClient.__init__">
<a class="viewcode-back" href="../../../dewey.llm.html#dewey.llm.litellm_client.LiteLLMClient.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">LiteLLMConfig</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the LiteLLM client.</span>

<span class="sd">        Args:</span>
<span class="sd">            config: Configuration for the client, defaults to environment-based config</span>
<span class="sd">            verbose: Whether to enable verbose logging</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Set verbose mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

        <span class="c1"># Try to load configuration from various sources</span>
        <span class="k">if</span> <span class="n">config</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Try loading configuration from various sources if no config object is provided</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># First try to load from Dewey config</span>
                <span class="kn">from</span><span class="w"> </span><span class="nn">dewey.core.base_script</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseScript</span>

                <span class="k">class</span><span class="w"> </span><span class="nc">TempBaseScript</span><span class="p">(</span><span class="n">BaseScript</span><span class="p">):</span>
                    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
                        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config_section</span><span class="o">=</span><span class="s2">&quot;llm&quot;</span><span class="p">)</span>

                    <span class="k">def</span><span class="w"> </span><span class="nf">execute</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
                        <span class="k">pass</span>  <span class="c1"># No-op execute needed for BaseScript</span>

                <span class="c1"># For test environments, we&#39;ll let the mocks handle yaml loading</span>
                <span class="c1"># In prod, we&#39;ll try loading from the different sources sequentially</span>
                <span class="k">if</span> <span class="n">DEWEY_CONFIG_PATH</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
                    <span class="c1"># Try loading from Dewey config</span>
                    <span class="n">temp_script</span> <span class="o">=</span> <span class="n">TempBaseScript</span><span class="p">()</span>
                    <span class="k">if</span> <span class="n">temp_script</span><span class="o">.</span><span class="n">config</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_config_from_dewey</span><span class="p">(</span><span class="n">temp_script</span><span class="o">.</span><span class="n">config</span><span class="p">)</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Loaded LiteLLM config from Dewey config.&quot;</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="n">AIDER_MODEL_METADATA_PATH</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
                        <span class="c1"># If Dewey config fails, try Aider</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_config_from_aider</span><span class="p">()</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Loaded LiteLLM config from Aider metadata.&quot;</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># Fall back to environment variables</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_config_from_env</span><span class="p">()</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                            <span class="s2">&quot;Loaded LiteLLM config from environment variables.&quot;</span>
                        <span class="p">)</span>
                <span class="k">elif</span> <span class="n">AIDER_MODEL_METADATA_PATH</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
                    <span class="c1"># If no Dewey config, try Aider</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_config_from_aider</span><span class="p">()</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Loaded LiteLLM config from Aider metadata.&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Fall back to environment variables if no sources available</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_config_from_env</span><span class="p">()</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Loaded LiteLLM config from environment variables.&quot;</span><span class="p">)</span>

            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Error loading config from Dewey/Aider: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Falling back to env vars.&quot;</span>
                <span class="p">)</span>
                <span class="c1"># Fall back to environment variables if any loading step fails unexpectedly</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_config_from_env</span><span class="p">()</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Use the provided config object if it exists</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Using provided LiteLLM config object.&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initialized LiteLLM client with model: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Set OpenAI API key if available</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">api_key</span><span class="p">:</span>
            <span class="n">litellm</span><span class="o">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">api_key</span>

        <span class="c1"># Set up litellm parameters</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">cache</span><span class="p">:</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LITELLM_CACHE_FOLDER&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">cache_folder</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Enabled caching in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">cache_folder</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Set up proxy if specified</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">proxy</span><span class="p">:</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LITELLM_PROXY&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">proxy</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using proxy: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">proxy</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>


    <span class="c1"># def _load_dewey_config(self) -&gt; Optional[Dict[str, Any]]:</span>
    <span class="c1">#     &quot;&quot;&quot;</span>
    <span class="c1">#     Load configuration from the Dewey config file.</span>
    <span class="c1">#</span>
    <span class="c1">#     Returns:</span>
    <span class="c1">#     Dictionary of configuration values, or None if loading fails</span>
    <span class="c1">#     &quot;&quot;&quot;</span>
    <span class="c1">#     try:</span>
    <span class="c1">#         if CONFIG_PATH.exists():</span>
    <span class="c1">#             with open(CONFIG_PATH, &quot;r&quot;) as f:</span>
    <span class="c1">#                 config = yaml.safe_load(f)</span>
    <span class="c1">#                 logger.debug(&quot;Loaded configuration from Dewey config&quot;)</span>
    <span class="c1">#                 return config</span>
    <span class="c1">#         else:</span>
    <span class="c1">#             logger.debug(f&quot;Dewey config file not found at {CONFIG_PATH}&quot;)</span>
    <span class="c1">#             return None</span>
    <span class="c1">#     except Exception as e:</span>
    <span class="c1">#         logger.warning(f&quot;Failed to load Dewey config: {e}&quot;)</span>
    <span class="c1">#         return None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_create_config_from_dewey</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dewey_config</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">LiteLLMConfig</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create LiteLLMConfig from Dewey config.</span>

<span class="sd">        Args:</span>
<span class="sd">            dewey_config: The loaded Dewey configuration object (dictionary or object)</span>

<span class="sd">        Returns:</span>
<span class="sd">            LiteLLMConfig populated with values from the Dewey config</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Handle both dictionary and object configurations</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dewey_config</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="c1"># If it&#39;s a dictionary, extract the llm section</span>
            <span class="n">llm_config</span> <span class="o">=</span> <span class="n">dewey_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;llm&quot;</span><span class="p">,</span> <span class="p">{})</span>

            <span class="c1"># Create config with values from the dictionary</span>
            <span class="n">config</span> <span class="o">=</span> <span class="n">LiteLLMConfig</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">llm_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">),</span>
                <span class="n">api_key</span><span class="o">=</span><span class="n">llm_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;api_key&quot;</span><span class="p">),</span>
                <span class="n">base_url</span><span class="o">=</span><span class="n">llm_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;base_url&quot;</span><span class="p">),</span>
                <span class="n">timeout</span><span class="o">=</span><span class="n">llm_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;timeout&quot;</span><span class="p">,</span> <span class="mi">60</span><span class="p">),</span>
                <span class="n">max_retries</span><span class="o">=</span><span class="n">llm_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;max_retries&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="n">fallback_models</span><span class="o">=</span><span class="n">llm_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;fallback_models&quot;</span><span class="p">,</span> <span class="p">[]),</span>
                <span class="n">proxy</span><span class="o">=</span><span class="n">llm_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;proxy&quot;</span><span class="p">),</span>
                <span class="n">cache</span><span class="o">=</span><span class="n">llm_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;cache&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
                <span class="n">cache_folder</span><span class="o">=</span><span class="n">llm_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;cache_folder&quot;</span><span class="p">,</span> <span class="s2">&quot;.litellm_cache&quot;</span><span class="p">),</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">llm_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;verbose&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
                <span class="n">litellm_provider</span><span class="o">=</span><span class="n">llm_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;provider&quot;</span><span class="p">),</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If it&#39;s an object, try to access its attributes</span>
            <span class="n">config</span> <span class="o">=</span> <span class="n">LiteLLMConfig</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">dewey_config</span><span class="p">,</span> <span class="s2">&quot;model&quot;</span><span class="p">,</span> <span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">),</span>
                <span class="n">api_key</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">dewey_config</span><span class="p">,</span> <span class="s2">&quot;api_key&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                <span class="n">base_url</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">dewey_config</span><span class="p">,</span> <span class="s2">&quot;base_url&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                <span class="n">timeout</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">dewey_config</span><span class="p">,</span> <span class="s2">&quot;timeout&quot;</span><span class="p">,</span> <span class="mi">60</span><span class="p">),</span>
                <span class="n">max_retries</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">dewey_config</span><span class="p">,</span> <span class="s2">&quot;max_retries&quot;</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="n">fallback_models</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">dewey_config</span><span class="p">,</span> <span class="s2">&quot;fallback_models&quot;</span><span class="p">,</span> <span class="p">[]),</span>
                <span class="n">proxy</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">dewey_config</span><span class="p">,</span> <span class="s2">&quot;proxy&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                <span class="n">cache</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">dewey_config</span><span class="p">,</span> <span class="s2">&quot;cache&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
                <span class="n">cache_folder</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">dewey_config</span><span class="p">,</span> <span class="s2">&quot;cache_folder&quot;</span><span class="p">,</span> <span class="s2">&quot;.litellm_cache&quot;</span><span class="p">),</span>
                <span class="n">verbose</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">dewey_config</span><span class="p">,</span> <span class="s2">&quot;verbose&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
                <span class="n">litellm_provider</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">dewey_config</span><span class="p">,</span> <span class="s2">&quot;provider&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
            <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Created config from Dewey config with model: </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">config</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_create_config_from_aider</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">LiteLLMConfig</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create LiteLLMConfig from Aider model metadata.</span>

<span class="sd">        Returns:</span>
<span class="sd">            LiteLLMConfig populated with values from Aider metadata</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Load Aider model metadata</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">dewey.llm.litellm_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_model_metadata_from_aider</span>

            <span class="n">model_metadata</span> <span class="o">=</span> <span class="n">load_model_metadata_from_aider</span><span class="p">()</span>

            <span class="c1"># Default to a reliable model if we can&#39;t determine one from Aider</span>
            <span class="n">default_model</span> <span class="o">=</span> <span class="s2">&quot;gpt-3.5-turbo&quot;</span>
            <span class="n">litellm_provider</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="c1"># Try to find a good model from the metadata</span>
            <span class="k">if</span> <span class="n">model_metadata</span><span class="p">:</span>
                <span class="c1"># Find models with LiteLLM provider specified</span>
                <span class="n">provider_models</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="n">name</span><span class="p">:</span> <span class="n">data</span>
                    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">model_metadata</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                    <span class="k">if</span> <span class="s2">&quot;litellm_provider&quot;</span> <span class="ow">in</span> <span class="n">data</span>
                <span class="p">}</span>

                <span class="c1"># Prioritize OpenAI, Anthropic, then any provider</span>
                <span class="k">for</span> <span class="n">provider</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;openai&quot;</span><span class="p">,</span> <span class="s2">&quot;anthropic&quot;</span><span class="p">]:</span>
                    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">provider_models</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;litellm_provider&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="n">provider</span><span class="p">:</span>
                            <span class="n">default_model</span> <span class="o">=</span> <span class="n">name</span>
                            <span class="n">litellm_provider</span> <span class="o">=</span> <span class="n">provider</span>
                            <span class="k">break</span>
                    <span class="k">if</span> <span class="n">litellm_provider</span><span class="p">:</span>
                        <span class="k">break</span>

                <span class="c1"># If no preferred provider found, use the first available</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">litellm_provider</span> <span class="ow">and</span> <span class="n">provider_models</span><span class="p">:</span>
                    <span class="n">name</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">provider_models</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
                    <span class="n">default_model</span> <span class="o">=</span> <span class="n">name</span>
                    <span class="n">litellm_provider</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;litellm_provider&quot;</span><span class="p">)</span>

            <span class="c1"># Create config with values from Aider or defaults</span>
            <span class="n">config</span> <span class="o">=</span> <span class="n">LiteLLMConfig</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">default_model</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;LITELLM_VERBOSE&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;true&quot;</span><span class="p">,</span>
                <span class="n">litellm_provider</span><span class="o">=</span><span class="n">litellm_provider</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Created config from Aider metadata with model: </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">config</span>

        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to create config from Aider metadata: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_config_from_env</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_create_config_from_env</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">LiteLLMConfig</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create LiteLLMConfig from environment variables.</span>

<span class="sd">        Returns:</span>
<span class="sd">            LiteLLMConfig populated with values from environment variables</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get environment variables with defaults</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">LiteLLMConfig</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;LITELLM_MODEL&quot;</span><span class="p">,</span> <span class="s2">&quot;gpt-3.5-turbo&quot;</span><span class="p">),</span>
            <span class="n">api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">),</span>
            <span class="n">organization_id</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;OPENAI_ORGANIZATION&quot;</span><span class="p">),</span>
            <span class="n">base_url</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;OPENAI_BASE_URL&quot;</span><span class="p">),</span>
            <span class="n">timeout</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;LITELLM_TIMEOUT&quot;</span><span class="p">,</span> <span class="s2">&quot;60&quot;</span><span class="p">)),</span>
            <span class="n">max_retries</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;LITELLM_MAX_RETRIES&quot;</span><span class="p">,</span> <span class="s2">&quot;3&quot;</span><span class="p">)),</span>
            <span class="n">proxy</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;LITELLM_PROXY&quot;</span><span class="p">),</span>
            <span class="n">cache</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;LITELLM_CACHE&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;true&quot;</span><span class="p">,</span>
            <span class="n">cache_folder</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;LITELLM_CACHE_FOLDER&quot;</span><span class="p">,</span> <span class="s2">&quot;.litellm_cache&quot;</span><span class="p">),</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;LITELLM_VERBOSE&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;true&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Parse fallback models if specified</span>
        <span class="n">fallback_env</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;LITELLM_FALLBACKS&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">fallback_env</span><span class="p">:</span>
            <span class="n">config</span><span class="o">.</span><span class="n">fallback_models</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">model</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">fallback_env</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>
            <span class="p">]</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Created config from environment with model: </span><span class="si">{</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">config</span>

<div class="viewcode-block" id="LiteLLMClient.generate_completion">
<a class="viewcode-back" href="../../../dewey.llm.html#dewey.llm.litellm_client.LiteLLMClient.generate_completion">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">generate_completion</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">messages</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Message</span><span class="p">],</span>
        <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.7</span><span class="p">,</span>
        <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">top_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">frequency_penalty</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">presence_penalty</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">stop</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">user</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">functions</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">function_call</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ModelResponse</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate a completion from messages.</span>

<span class="sd">        Args:</span>
<span class="sd">            messages: List of Message objects</span>
<span class="sd">            model: Model to use, defaults to config model</span>
<span class="sd">            temperature: Sampling temperature</span>
<span class="sd">            max_tokens: Maximum tokens to generate</span>
<span class="sd">            top_p: Nucleus sampling parameter</span>
<span class="sd">            frequency_penalty: Penalize repeat tokens</span>
<span class="sd">            presence_penalty: Penalize repeat topics</span>
<span class="sd">            stop: Stop sequences</span>
<span class="sd">            user: User identifier</span>
<span class="sd">            functions: Function schemas for function calling</span>
<span class="sd">            function_call: Function call configuration</span>

<span class="sd">        Returns:</span>
<span class="sd">            LiteLLM ModelResponse</span>

<span class="sd">        Raises:</span>
<span class="sd">            LLMResponseError: For general response errors</span>
<span class="sd">            LLMConnectionError: For connection issues</span>
<span class="sd">            LLMAuthenticationError: For authentication issues</span>
<span class="sd">            LLMRateLimitError: For rate limiting issues</span>
<span class="sd">            LLMTimeoutError: For timeout issues</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Convert Message objects to dictionaries</span>
            <span class="n">messages_dict</span> <span class="o">=</span> <span class="p">[</span>
                <span class="p">{</span>
                    <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="n">msg</span><span class="o">.</span><span class="n">role</span><span class="p">,</span>
                    <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">msg</span><span class="o">.</span><span class="n">content</span><span class="p">,</span>
                    <span class="o">**</span><span class="p">({</span><span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">msg</span><span class="o">.</span><span class="n">name</span><span class="p">}</span> <span class="k">if</span> <span class="n">msg</span><span class="o">.</span><span class="n">name</span> <span class="k">else</span> <span class="p">{}),</span>
                <span class="p">}</span>
                <span class="k">for</span> <span class="n">msg</span> <span class="ow">in</span> <span class="n">messages</span>
            <span class="p">]</span>

            <span class="c1"># Use model from parameters or config</span>
            <span class="n">model_name</span> <span class="o">=</span> <span class="n">model</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span>

            <span class="c1"># Log the request if verbose</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Generating completion with model </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span><span class="si">}</span><span class="s2"> messages, temperature=</span><span class="si">{</span><span class="n">temperature</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="c1"># Call litellm completion</span>
            <span class="n">response</span> <span class="o">=</span> <span class="n">completion</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
                <span class="n">messages</span><span class="o">=</span><span class="n">messages_dict</span><span class="p">,</span>
                <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
                <span class="n">max_tokens</span><span class="o">=</span><span class="n">max_tokens</span><span class="p">,</span>
                <span class="n">top_p</span><span class="o">=</span><span class="n">top_p</span><span class="p">,</span>
                <span class="n">frequency_penalty</span><span class="o">=</span><span class="n">frequency_penalty</span><span class="p">,</span>
                <span class="n">presence_penalty</span><span class="o">=</span><span class="n">presence_penalty</span><span class="p">,</span>
                <span class="n">stop</span><span class="o">=</span><span class="n">stop</span><span class="p">,</span>
                <span class="n">user</span><span class="o">=</span><span class="n">user</span><span class="p">,</span>
                <span class="n">functions</span><span class="o">=</span><span class="n">functions</span><span class="p">,</span>
                <span class="n">function_call</span><span class="o">=</span><span class="n">function_call</span><span class="p">,</span>
                <span class="n">timeout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">timeout</span><span class="p">,</span>
                <span class="n">max_retries</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_retries</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Calculate cost for logging</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="n">completion_cost</span><span class="p">(</span>
                <span class="n">completion_response</span><span class="o">=</span><span class="n">response</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Completion cost: $</span><span class="si">{</span><span class="n">cost</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">response</span>

        <span class="k">except</span> <span class="n">litellm</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">RateLimitError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Rate limit exceeded: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">LLMRateLimitError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Rate limit exceeded: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">litellm</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">AuthenticationError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Authentication error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">LLMAuthenticationError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Authentication error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">litellm</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">APIConnectionError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Connection error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">LLMConnectionError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Connection error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">litellm</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">APITimeoutError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Request timed out: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">LLMTimeoutError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Request timed out: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">litellm</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">BadRequestError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Bad request: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">LLMResponseError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Bad request: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to generate completion: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">LLMResponseError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to generate completion: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="LiteLLMClient.generate_embedding">
<a class="viewcode-back" href="../../../dewey.llm.html#dewey.llm.litellm_client.LiteLLMClient.generate_embedding">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">generate_embedding</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_text</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">encoding_format</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;float&quot;</span><span class="p">,</span>
        <span class="n">dimensions</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">user</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate embeddings for input text.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_text: String or list of strings to embed</span>
<span class="sd">            model: Model to use, defaults to a suitable embedding model</span>
<span class="sd">            encoding_format: Encoding format for vectors</span>
<span class="sd">            dimensions: Dimensionality of output vectors</span>
<span class="sd">            user: User identifier</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dictionary with embedding data</span>

<span class="sd">        Raises:</span>
<span class="sd">            LLMResponseError: For general response errors</span>
<span class="sd">            LLMConnectionError: For connection issues</span>
<span class="sd">            LLMAuthenticationError: For authentication issues</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Use model from parameters, or a default embedding model</span>
            <span class="n">model_name</span> <span class="o">=</span> <span class="n">model</span> <span class="ow">or</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                <span class="s2">&quot;LITELLM_EMBEDDING_MODEL&quot;</span><span class="p">,</span> <span class="s2">&quot;text-embedding-ada-002&quot;</span>
            <span class="p">)</span>

            <span class="c1"># Log the request if verbose</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="n">input_len</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="nb">len</span><span class="p">(</span><span class="n">input_text</span><span class="p">)</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_text</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span>
                    <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_text</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                    <span class="k">if</span> <span class="n">input_text</span>
                    <span class="k">else</span> <span class="mi">0</span>
                <span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Generating embedding with model </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;input length </span><span class="si">{</span><span class="n">input_len</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="c1"># Call litellm embedding</span>
            <span class="n">response</span> <span class="o">=</span> <span class="n">embedding</span><span class="p">(</span>
                <span class="n">model</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
                <span class="nb">input</span><span class="o">=</span><span class="n">input_text</span><span class="p">,</span>
                <span class="n">encoding_format</span><span class="o">=</span><span class="n">encoding_format</span><span class="p">,</span>
                <span class="n">dimensions</span><span class="o">=</span><span class="n">dimensions</span><span class="p">,</span>
                <span class="n">user</span><span class="o">=</span><span class="n">user</span><span class="p">,</span>
                <span class="n">timeout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">timeout</span><span class="p">,</span>
                <span class="n">max_retries</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_retries</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">return</span> <span class="n">response</span>

        <span class="k">except</span> <span class="n">litellm</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">RateLimitError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Rate limit exceeded: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">LLMRateLimitError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Rate limit exceeded: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">litellm</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">AuthenticationError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Authentication error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">LLMAuthenticationError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Authentication error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">litellm</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">APIConnectionError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Connection error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">LLMConnectionError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Connection error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">litellm</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">APITimeoutError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Request timed out: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">LLMTimeoutError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Request timed out: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to generate embedding: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">LLMResponseError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to generate embedding: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="LiteLLMClient.get_model_details">
<a class="viewcode-back" href="../../../dewey.llm.html#dewey.llm.litellm_client.LiteLLMClient.get_model_details">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_model_details</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get details about a specific model.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: Model name to get details for, defaults to config model</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dictionary with model details</span>

<span class="sd">        Raises:</span>
<span class="sd">            LLMResponseError: If model details cannot be retrieved</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">model_name</span> <span class="o">=</span> <span class="n">model</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">model</span>
            <span class="n">model_info</span> <span class="o">=</span> <span class="n">get_model_info</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_name</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">model_info</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to get model details: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">LLMResponseError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to get model details: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>
</div>

</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../index.html">Dewey (TUI)</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../index.html">Documentation overview</a><ul>
  <li><a href="../../index.html">Module code</a><ul>
  <li><a href="../../dewey.html">dewey</a><ul>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2025, Sloane Ortel.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.2.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
    </div>

    

    
  </body>
</html>